Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
# 知识点

- 线性分类
- 激活函数的使用
- Softmax使用
- 交叉熵代价函数


# 分类与分类函数

《道德经》第四十二章中，老子说：道生一，一生二，二生三，三生万物。

回归和分类，是神经网络擅长的两种工作。回归就是拟合，分类就是把样本通过训练分成指定的几个类别。老子说的“一生二，二生三，三生万物”，其中的“一”就是回归，“二”就是二分类，“三”就是多分类。二分类和多分类在实际使用种略有不同。


## 二分类问题

我们先看看如何用神经网络在两组不同标签的样本之间画一条明显的分界线。这条分界线可以是直线，如我们在第七章要讲的，也可以是曲线，如我们在第九章要讲的。这就是二分类问题。如果只画一条线的画，我们用一支笔，即一个神经元，就可以达到目的。

|线性二分类|非线性二分类|
|---|---|
|<img src=".\Images\6\linear_binary.png"/>|<img src=".\Images\6\non_linear_binary.png"/>|


- 神经网络设计

这种情况下，我们只需要在网络的最后一层，配置一个神经元就可以搞定。

<img src=".\Images\1\NeuranCell.png"/>

$$Z = W \cdot X + B$$

- 二分类函数 - Sigmoid

$$
A=Sigmoid(Z)
$$

<img src=".\Images\1\activation.png"/>

- 损失函数 - 交叉熵 Cross Entropy

$$
J(w,b) = -[YlnA+(1-Y)ln(1-A)]
$$

分类的方式是，可以指定当A > 0.5时是正例，A <= 0.5时就是反例。或者根据实际情况指定别的阈值比如0.3，0.8等等。


# 多分类问题

如果有三个以上的分类同时存在，我们需要对每一类别分配一个神经元，这个神经元的作用是根据前端输入的各种数据，先做线性处理（Y=WX+B)，然后做一次非线性处理，计算每个样本在每个类别中的预测概率，再和标签中的类别比较，看看预测是否准确，如果准确，则奖励这个预测，给与正反馈；如果不准确，则惩罚这个预测，给与负反馈。两类反馈都反向传播到神经网络系统中去调整参数。

|线性多分类|非线性多分类|
|---|---|
|<img src=".\Images\6\linear_multiple.png"/>|<img src=".\Images\6\non_linear_multiple.png"/>|

多分类问题的第二种解法，是用one vs others，即单独对每一类都做一个和其他类的二分类。

<img src=".\Images\6\one_vs_multiple.png"/>


- 多分类函数 Softmax

$$
a_i = \frac{e^{z_i}}{\sum^m_{j=0} e^{z_j}}
$$

- 损失函数

$$
J(w,b) = -YlnA
$$


**本章要讲述的是线性二分类和线性多分类问题的解决方案。**








# 二分类
在输出层使用单个神经元输出，使用Sigmoid激活函数和下面这种交叉熵损失函数：
$$
Z = W * X + B \tag{矩阵计算}
$$

$$
A=Sigmoid(Z) \tag{Logistic激活函数用于二分类}
$$

$$
Loss = -[Y * lnA+(1-Y) * ln(1-A)] \tag{二分类交叉熵函数}
$$

|<img src=".\Images\1\NeuranCell.png" width="400"/>|<img src=".\Images\1\activation.png" width="400"/>|
|---|---|

分类的方式是，可以指定当A > 0.5时是正例，A <= 0.5时就是反例。或者根据实际情况指定别的阈值比如0.3，0.8等等。


# 多分类（大于两类）
在输出层使用多个神经元输出，并对多个神经元使用Softmax分类函数和下面这种交叉熵损失函数：

$$
Z = W \times X+B \tag{矩阵运算}
$$
$$
A=Softmax(Z) \tag{多分类函数}
$$
$$
Loss = -Y * lnA \tag{多分类交叉熵函数}
$$

|<img src=".\Images\7\MultipleClassifierNN.png">|<img src=".\Images\7\softmax.png">|
|---|---|

