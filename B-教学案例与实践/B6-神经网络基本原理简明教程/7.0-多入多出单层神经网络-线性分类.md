Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可
  
# 知识点

- 线性分类
- 激活函数的使用
- Softmax使用
- 交叉熵代价函数


# 分类与分类函数

《道德经》第四十二章中，老子说：道生一，一生二，二生三，三生万物。

“一”就是线性，“二”就是二分类，“三”就是多分类。

## 二分类问题

我们先看看如何用神经网络在两组不同标签的样本之间画一条明显的分界线。这条分界线可以是直线，如我们在第七章要讲的，也可以是曲线，如我们在第九章要讲的。这就是二分类问题。如果只画一条线的画，我们用一支笔，即一个神经元，就可以达到目的。

|线性二分类|非线性二分类|
|---|---|
|<img src=".\Images\6\linear_binary.png"/>|<img src=".\Images\6\non_linear_binary.png"/>|


- 神经网络设计

这种情况下，我们只需要在网络的最后一层，配置一个神经元就可以搞定。

<img src=".\Images\1\NeuranCell.png"/>

$$Z = W \cdot X + B$$

- 二分类函数 - Sigmoid

$$
A=Sigmoid(Z)
$$

<img src=".\Images\1\activation.png"/>

- 损失函数 - 交叉熵 Cross Entropy

$$
J(w,b) = -[YlnA+(1-Y)ln(1-A)]
$$

分类的方式是，可以指定当A > 0.5时是正例，A <= 0.5时就是反例。或者根据实际情况指定别的阈值比如0.3，0.8等等。


# 多分类问题

如果有三个以上的分类同时存在，我们需要对每一类别分配一个神经元，这个神经元的作用是根据前端输入的各种数据，先做线性处理（Y=WX+B)，然后做一次非线性处理，计算每个样本在每个类别中的预测概率，再和标签中的类别比较，看看预测是否准确，如果准确，则奖励这个预测，给与正反馈；如果不准确，则惩罚这个预测，给与负反馈。两类反馈都反向传播到神经网络系统中去调整参数。

|线性多分类|非线性多分类|
|---|---|
|<img src=".\Images\6\linear_multiple.png"/>|<img src=".\Images\6\non_linear_multiple.png"/>|

多分类问题的第二种解法，是用one vs others，即单独对每一类都做一个和其他类的二分类。

<img src=".\Images\6\one_vs_multiple.png"/>


- 多分类函数 Softmax

$$
a_i = \frac{e^{z_i}}{\sum^m_{j=0} e^{z_j}}
$$

- 损失函数

$$
J(w,b) = -YlnA
$$


**本章要讲述的是线性二分类和线性多分类问题的解决方案。**




